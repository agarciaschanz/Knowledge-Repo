{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "testgv",
      "language": "python",
      "name": "testgv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Smartphone_Activity_Detector.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHZMksSby0C"
      },
      "source": [
        "# Neural Network Smartphone Activity Detector\n",
        "\n",
        "In this activity, you will train a neural network to use smartphone data to predict the activity of the user. \n",
        "\n",
        "This dataset has already been separated into input features and target activities. Additional information on the dataset can be found here. \n",
        "\n",
        "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfrsfVyby0F"
      },
      "source": [
        "### Data Pre-Processing\n",
        "\n",
        "Prepare the data for the neural network. This includes splitting the data into a training and testing dataset, Scaling the data, and encoding the categorical target values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoXtMPdJby0G"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "sVTrTawMb2ul",
        "outputId": "c3172c95-eff9-4cb0-b0ba-b95d5073acb1"
      },
      "source": [
        "# Upload data to Colab\n",
        "from google.colab import files\n",
        "\n",
        "csv_file = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b40d6974-9e2b-47a5-9604-9a9668cda8ca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b40d6974-9e2b-47a5-9604-9a9668cda8ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving features.csv to features.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "i2uJV_X2by0G",
        "outputId": "ad49c428-f968-4336-ff95-ce54bc83f08b"
      },
      "source": [
        "# Read the input features into `X`\n",
        "X = pd.read_csv(\"features.csv\", header=None)\n",
        "X.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>524</th>\n",
              "      <th>525</th>\n",
              "      <th>526</th>\n",
              "      <th>527</th>\n",
              "      <th>528</th>\n",
              "      <th>529</th>\n",
              "      <th>530</th>\n",
              "      <th>531</th>\n",
              "      <th>532</th>\n",
              "      <th>533</th>\n",
              "      <th>534</th>\n",
              "      <th>535</th>\n",
              "      <th>536</th>\n",
              "      <th>537</th>\n",
              "      <th>538</th>\n",
              "      <th>539</th>\n",
              "      <th>540</th>\n",
              "      <th>541</th>\n",
              "      <th>542</th>\n",
              "      <th>543</th>\n",
              "      <th>544</th>\n",
              "      <th>545</th>\n",
              "      <th>546</th>\n",
              "      <th>547</th>\n",
              "      <th>548</th>\n",
              "      <th>549</th>\n",
              "      <th>550</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "      <th>555</th>\n",
              "      <th>556</th>\n",
              "      <th>557</th>\n",
              "      <th>558</th>\n",
              "      <th>559</th>\n",
              "      <th>560</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043580</td>\n",
              "      <td>-0.005970</td>\n",
              "      <td>-0.035054</td>\n",
              "      <td>-0.995381</td>\n",
              "      <td>-0.988366</td>\n",
              "      <td>-0.937382</td>\n",
              "      <td>-0.995007</td>\n",
              "      <td>-0.988816</td>\n",
              "      <td>-0.953325</td>\n",
              "      <td>-0.794796</td>\n",
              "      <td>-0.744893</td>\n",
              "      <td>-0.648447</td>\n",
              "      <td>0.841796</td>\n",
              "      <td>0.708440</td>\n",
              "      <td>0.651716</td>\n",
              "      <td>-0.975752</td>\n",
              "      <td>-0.999950</td>\n",
              "      <td>-0.999888</td>\n",
              "      <td>-0.998014</td>\n",
              "      <td>-0.993999</td>\n",
              "      <td>-0.991980</td>\n",
              "      <td>-0.970970</td>\n",
              "      <td>-0.547095</td>\n",
              "      <td>-0.700974</td>\n",
              "      <td>-0.622697</td>\n",
              "      <td>0.921884</td>\n",
              "      <td>-0.719483</td>\n",
              "      <td>0.342168</td>\n",
              "      <td>-0.161318</td>\n",
              "      <td>0.266049</td>\n",
              "      <td>-0.274351</td>\n",
              "      <td>0.267205</td>\n",
              "      <td>-0.020958</td>\n",
              "      <td>0.382610</td>\n",
              "      <td>-0.501748</td>\n",
              "      <td>0.512463</td>\n",
              "      <td>-0.206337</td>\n",
              "      <td>0.376778</td>\n",
              "      <td>0.435172</td>\n",
              "      <td>0.660199</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999918</td>\n",
              "      <td>-0.991736</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.349260</td>\n",
              "      <td>-0.517127</td>\n",
              "      <td>-0.801006</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.961301</td>\n",
              "      <td>-0.974129</td>\n",
              "      <td>-0.956013</td>\n",
              "      <td>-0.989894</td>\n",
              "      <td>-0.980135</td>\n",
              "      <td>-0.999240</td>\n",
              "      <td>-0.992673</td>\n",
              "      <td>-0.701291</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.132480</td>\n",
              "      <td>0.565697</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>-0.991994</td>\n",
              "      <td>-0.990877</td>\n",
              "      <td>-0.990169</td>\n",
              "      <td>-0.992521</td>\n",
              "      <td>-0.991044</td>\n",
              "      <td>-0.991994</td>\n",
              "      <td>-0.999937</td>\n",
              "      <td>-0.990537</td>\n",
              "      <td>-0.871306</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.012236</td>\n",
              "      <td>-0.314848</td>\n",
              "      <td>-0.713308</td>\n",
              "      <td>-0.112754</td>\n",
              "      <td>0.030400</td>\n",
              "      <td>-0.464761</td>\n",
              "      <td>-0.018446</td>\n",
              "      <td>-0.841559</td>\n",
              "      <td>0.179913</td>\n",
              "      <td>-0.051718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.039480</td>\n",
              "      <td>-0.002131</td>\n",
              "      <td>-0.029067</td>\n",
              "      <td>-0.998348</td>\n",
              "      <td>-0.982945</td>\n",
              "      <td>-0.971273</td>\n",
              "      <td>-0.998702</td>\n",
              "      <td>-0.983315</td>\n",
              "      <td>-0.974000</td>\n",
              "      <td>-0.802537</td>\n",
              "      <td>-0.736338</td>\n",
              "      <td>-0.712415</td>\n",
              "      <td>0.838758</td>\n",
              "      <td>0.708440</td>\n",
              "      <td>0.659340</td>\n",
              "      <td>-0.987427</td>\n",
              "      <td>-0.999993</td>\n",
              "      <td>-0.999826</td>\n",
              "      <td>-0.999411</td>\n",
              "      <td>-0.998918</td>\n",
              "      <td>-0.985482</td>\n",
              "      <td>-0.973481</td>\n",
              "      <td>-0.781973</td>\n",
              "      <td>-0.534604</td>\n",
              "      <td>-0.593165</td>\n",
              "      <td>0.607435</td>\n",
              "      <td>-0.266783</td>\n",
              "      <td>0.275882</td>\n",
              "      <td>0.200417</td>\n",
              "      <td>0.131266</td>\n",
              "      <td>-0.149017</td>\n",
              "      <td>0.292436</td>\n",
              "      <td>-0.192986</td>\n",
              "      <td>0.217496</td>\n",
              "      <td>-0.089175</td>\n",
              "      <td>0.059909</td>\n",
              "      <td>-0.236609</td>\n",
              "      <td>-0.012696</td>\n",
              "      <td>-0.072711</td>\n",
              "      <td>0.578649</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999867</td>\n",
              "      <td>-0.991506</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.841270</td>\n",
              "      <td>0.533688</td>\n",
              "      <td>-0.625993</td>\n",
              "      <td>-0.898311</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.983313</td>\n",
              "      <td>-0.982951</td>\n",
              "      <td>-0.987406</td>\n",
              "      <td>-0.992134</td>\n",
              "      <td>-0.988296</td>\n",
              "      <td>-0.999811</td>\n",
              "      <td>-0.993996</td>\n",
              "      <td>-0.720683</td>\n",
              "      <td>-0.948718</td>\n",
              "      <td>-0.268979</td>\n",
              "      <td>-0.364219</td>\n",
              "      <td>-0.723724</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.996580</td>\n",
              "      <td>-0.995671</td>\n",
              "      <td>-0.996939</td>\n",
              "      <td>-0.994436</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.999981</td>\n",
              "      <td>-0.994623</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.202804</td>\n",
              "      <td>-0.603199</td>\n",
              "      <td>-0.860677</td>\n",
              "      <td>0.053477</td>\n",
              "      <td>-0.007435</td>\n",
              "      <td>-0.732626</td>\n",
              "      <td>0.703511</td>\n",
              "      <td>-0.845092</td>\n",
              "      <td>0.180261</td>\n",
              "      <td>-0.047436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039978</td>\n",
              "      <td>-0.005153</td>\n",
              "      <td>-0.022651</td>\n",
              "      <td>-0.995482</td>\n",
              "      <td>-0.977314</td>\n",
              "      <td>-0.984760</td>\n",
              "      <td>-0.996415</td>\n",
              "      <td>-0.975835</td>\n",
              "      <td>-0.985973</td>\n",
              "      <td>-0.798477</td>\n",
              "      <td>-0.736338</td>\n",
              "      <td>-0.712415</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.705008</td>\n",
              "      <td>0.674551</td>\n",
              "      <td>-0.988528</td>\n",
              "      <td>-0.999972</td>\n",
              "      <td>-0.999719</td>\n",
              "      <td>-0.999803</td>\n",
              "      <td>-0.996898</td>\n",
              "      <td>-0.976781</td>\n",
              "      <td>-0.986754</td>\n",
              "      <td>-0.688176</td>\n",
              "      <td>-0.520514</td>\n",
              "      <td>-0.593165</td>\n",
              "      <td>0.272262</td>\n",
              "      <td>-0.056424</td>\n",
              "      <td>0.322283</td>\n",
              "      <td>-0.273292</td>\n",
              "      <td>0.037180</td>\n",
              "      <td>-0.133612</td>\n",
              "      <td>0.332487</td>\n",
              "      <td>-0.240491</td>\n",
              "      <td>0.348733</td>\n",
              "      <td>-0.195409</td>\n",
              "      <td>0.229436</td>\n",
              "      <td>-0.316816</td>\n",
              "      <td>-0.123889</td>\n",
              "      <td>-0.181137</td>\n",
              "      <td>0.608219</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999845</td>\n",
              "      <td>-0.987029</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.661975</td>\n",
              "      <td>-0.725887</td>\n",
              "      <td>-0.926663</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.986019</td>\n",
              "      <td>-0.984533</td>\n",
              "      <td>-0.991701</td>\n",
              "      <td>-0.995857</td>\n",
              "      <td>-0.989255</td>\n",
              "      <td>-0.999854</td>\n",
              "      <td>-0.993256</td>\n",
              "      <td>-0.736521</td>\n",
              "      <td>-0.794872</td>\n",
              "      <td>-0.212429</td>\n",
              "      <td>-0.564868</td>\n",
              "      <td>-0.874594</td>\n",
              "      <td>-0.995034</td>\n",
              "      <td>-0.995308</td>\n",
              "      <td>-0.994868</td>\n",
              "      <td>-0.996133</td>\n",
              "      <td>-0.995863</td>\n",
              "      <td>-0.995034</td>\n",
              "      <td>-0.999973</td>\n",
              "      <td>-0.993834</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.555556</td>\n",
              "      <td>0.440079</td>\n",
              "      <td>-0.404427</td>\n",
              "      <td>-0.761847</td>\n",
              "      <td>-0.118559</td>\n",
              "      <td>0.177899</td>\n",
              "      <td>0.100699</td>\n",
              "      <td>0.808529</td>\n",
              "      <td>-0.849230</td>\n",
              "      <td>0.180610</td>\n",
              "      <td>-0.042271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039785</td>\n",
              "      <td>-0.011809</td>\n",
              "      <td>-0.028916</td>\n",
              "      <td>-0.996194</td>\n",
              "      <td>-0.988569</td>\n",
              "      <td>-0.993256</td>\n",
              "      <td>-0.996994</td>\n",
              "      <td>-0.988526</td>\n",
              "      <td>-0.993135</td>\n",
              "      <td>-0.798477</td>\n",
              "      <td>-0.752778</td>\n",
              "      <td>-0.722186</td>\n",
              "      <td>0.834002</td>\n",
              "      <td>0.705008</td>\n",
              "      <td>0.673208</td>\n",
              "      <td>-0.990389</td>\n",
              "      <td>-0.999978</td>\n",
              "      <td>-0.999783</td>\n",
              "      <td>-0.999815</td>\n",
              "      <td>-0.996949</td>\n",
              "      <td>-0.989437</td>\n",
              "      <td>-0.992440</td>\n",
              "      <td>-0.715103</td>\n",
              "      <td>-0.860988</td>\n",
              "      <td>-0.916429</td>\n",
              "      <td>0.062816</td>\n",
              "      <td>0.082940</td>\n",
              "      <td>0.200566</td>\n",
              "      <td>-0.378262</td>\n",
              "      <td>0.090063</td>\n",
              "      <td>-0.209264</td>\n",
              "      <td>0.316530</td>\n",
              "      <td>-0.090862</td>\n",
              "      <td>0.396383</td>\n",
              "      <td>-0.353643</td>\n",
              "      <td>0.503754</td>\n",
              "      <td>-0.490389</td>\n",
              "      <td>-0.304759</td>\n",
              "      <td>-0.362708</td>\n",
              "      <td>0.506602</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999894</td>\n",
              "      <td>-0.988427</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.680038</td>\n",
              "      <td>-0.702305</td>\n",
              "      <td>-0.907781</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.987827</td>\n",
              "      <td>-0.987057</td>\n",
              "      <td>-0.987801</td>\n",
              "      <td>-0.996334</td>\n",
              "      <td>-0.989413</td>\n",
              "      <td>-0.999876</td>\n",
              "      <td>-0.989153</td>\n",
              "      <td>-0.720891</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.043398</td>\n",
              "      <td>-0.257142</td>\n",
              "      <td>-0.516341</td>\n",
              "      <td>-0.995224</td>\n",
              "      <td>-0.995417</td>\n",
              "      <td>-0.995951</td>\n",
              "      <td>-0.995346</td>\n",
              "      <td>-0.995728</td>\n",
              "      <td>-0.995224</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995305</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.430891</td>\n",
              "      <td>-0.138373</td>\n",
              "      <td>-0.491604</td>\n",
              "      <td>-0.036788</td>\n",
              "      <td>-0.012892</td>\n",
              "      <td>0.640011</td>\n",
              "      <td>-0.485366</td>\n",
              "      <td>-0.848947</td>\n",
              "      <td>0.181907</td>\n",
              "      <td>-0.040826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.038758</td>\n",
              "      <td>-0.002289</td>\n",
              "      <td>-0.023863</td>\n",
              "      <td>-0.998241</td>\n",
              "      <td>-0.986774</td>\n",
              "      <td>-0.993115</td>\n",
              "      <td>-0.998216</td>\n",
              "      <td>-0.986479</td>\n",
              "      <td>-0.993825</td>\n",
              "      <td>-0.801982</td>\n",
              "      <td>-0.746505</td>\n",
              "      <td>-0.717858</td>\n",
              "      <td>0.838581</td>\n",
              "      <td>0.705854</td>\n",
              "      <td>0.673208</td>\n",
              "      <td>-0.995057</td>\n",
              "      <td>-0.999992</td>\n",
              "      <td>-0.999882</td>\n",
              "      <td>-0.999908</td>\n",
              "      <td>-0.997772</td>\n",
              "      <td>-0.987726</td>\n",
              "      <td>-0.995109</td>\n",
              "      <td>-0.836774</td>\n",
              "      <td>-0.589200</td>\n",
              "      <td>-0.773771</td>\n",
              "      <td>0.312105</td>\n",
              "      <td>-0.095254</td>\n",
              "      <td>0.194399</td>\n",
              "      <td>-0.007998</td>\n",
              "      <td>0.266740</td>\n",
              "      <td>-0.318965</td>\n",
              "      <td>0.409731</td>\n",
              "      <td>-0.224589</td>\n",
              "      <td>0.520354</td>\n",
              "      <td>-0.319167</td>\n",
              "      <td>0.234376</td>\n",
              "      <td>-0.102650</td>\n",
              "      <td>-0.154974</td>\n",
              "      <td>-0.189796</td>\n",
              "      <td>0.598515</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.999941</td>\n",
              "      <td>-0.994542</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.560592</td>\n",
              "      <td>-0.529957</td>\n",
              "      <td>-0.857124</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.989051</td>\n",
              "      <td>-0.987932</td>\n",
              "      <td>-0.992145</td>\n",
              "      <td>-0.998404</td>\n",
              "      <td>-0.991433</td>\n",
              "      <td>-0.999902</td>\n",
              "      <td>-0.989339</td>\n",
              "      <td>-0.763372</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>-0.270529</td>\n",
              "      <td>-0.539596</td>\n",
              "      <td>-0.833661</td>\n",
              "      <td>-0.995096</td>\n",
              "      <td>-0.995645</td>\n",
              "      <td>-0.995508</td>\n",
              "      <td>-0.995683</td>\n",
              "      <td>-0.997414</td>\n",
              "      <td>-0.995096</td>\n",
              "      <td>-0.999974</td>\n",
              "      <td>-0.995566</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.137735</td>\n",
              "      <td>-0.366214</td>\n",
              "      <td>-0.702490</td>\n",
              "      <td>0.123320</td>\n",
              "      <td>0.122542</td>\n",
              "      <td>0.693578</td>\n",
              "      <td>-0.615971</td>\n",
              "      <td>-0.848164</td>\n",
              "      <td>0.185124</td>\n",
              "      <td>-0.037080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       558       559       560\n",
              "0  0.043580 -0.005970 -0.035054  ... -0.841559  0.179913 -0.051718\n",
              "1  0.039480 -0.002131 -0.029067  ... -0.845092  0.180261 -0.047436\n",
              "2  0.039978 -0.005153 -0.022651  ... -0.849230  0.180610 -0.042271\n",
              "3  0.039785 -0.011809 -0.028916  ... -0.848947  0.181907 -0.040826\n",
              "4  0.038758 -0.002289 -0.023863  ... -0.848164  0.185124 -0.037080\n",
              "\n",
              "[5 rows x 561 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dVzqGN06cFhE",
        "outputId": "8ba84473-0503-4b8f-c9d5-f71ddfca64c0"
      },
      "source": [
        "# Upload data to Colab\n",
        "csv_file = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ed18dfe-d95e-4490-af01-3b8b42507c7e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ed18dfe-d95e-4490-af01-3b8b42507c7e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving target.csv to target.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "dNwj6V7kby0H",
        "outputId": "716d67a3-0b7d-4ade-8bc4-089eb3b033c4"
      },
      "source": [
        "# Read the target values into `y`\n",
        "y = pd.read_csv(\"target.csv\")\n",
        "y.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>standing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   activity\n",
              "0  standing\n",
              "1  standing\n",
              "2  standing\n",
              "3  standing\n",
              "4  standing"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EVCLESQby0I",
        "outputId": "fb1face2-7e63-445c-a740-903b4c7a3374"
      },
      "source": [
        "y.activity.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "standing              1423\n",
              "laying                1413\n",
              "sitting               1293\n",
              "walking               1226\n",
              "walking_upstairs      1073\n",
              "walking_downstairs     987\n",
              "stand_to_lie            90\n",
              "sit_to_lie              75\n",
              "lie_to_sit              60\n",
              "lie_to_stand            57\n",
              "stand_to_sit            47\n",
              "sit_to_stand            23\n",
              "Name: activity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW1tnHBQby0I"
      },
      "source": [
        "# Split the dataset into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acErW392by0J"
      },
      "source": [
        "# Scale the training and testing input features using StandardScaler\n",
        "X_scaler = StandardScaler()\n",
        "X_scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFWQpw3Wby0J",
        "outputId": "7811e660-4b61-410f-aeef-3d8a7231038d"
      },
      "source": [
        "# Apply One-hot encoding to the target labels\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(y_train)\n",
        "\n",
        "encoded_y_train = enc.transform(y_train).toarray()\n",
        "encoded_y_test = enc.transform(y_test).toarray()\n",
        "encoded_y_train[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPE6GHzhby0K"
      },
      "source": [
        "# Build a Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LyIVL2Pby0K"
      },
      "source": [
        "# Create a sequential model\n",
        "model = Sequential()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BflNy17by0L"
      },
      "source": [
        "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
        "model.add(Dense(100, activation='relu', input_dim=X_train_scaled.shape[1]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYSEvJvby0L"
      },
      "source": [
        "# The output layer has 12 columns that are one-hot encoded\n",
        "y_train.activity.value_counts()\n",
        "number_outputs = 12"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7e2oa11by0L"
      },
      "source": [
        "# Add output layer using 12 output nodes\n",
        "model.add(Dense(number_outputs, activation=\"softmax\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgAlZYkdby0L"
      },
      "source": [
        "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
        "# and add accuracy to the training metrics\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EXEt8AQby0M",
        "outputId": "4e96e0b7-443d-4db4-99d4-609483aef0ec"
      },
      "source": [
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               56200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                1212      \n",
            "=================================================================\n",
            "Total params: 57,412\n",
            "Trainable params: 57,412\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CF2DJZRby0M",
        "outputId": "68e10b27-698a-4e7b-aefe-a02f66081e7f"
      },
      "source": [
        "# Use the training data to fit (train) the model\n",
        "# @NOTE: Experiment with the number of training epochs to find the minimum iterations required to achieve a good accuracy\n",
        "model.fit(\n",
        "    X_train_scaled,\n",
        "    encoded_y_train,\n",
        "    epochs=30,\n",
        "    shuffle=True,\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "183/183 - 1s - loss: 0.3800 - accuracy: 0.8654\n",
            "Epoch 2/30\n",
            "183/183 - 0s - loss: 0.1247 - accuracy: 0.9585\n",
            "Epoch 3/30\n",
            "183/183 - 0s - loss: 0.0865 - accuracy: 0.9720\n",
            "Epoch 4/30\n",
            "183/183 - 0s - loss: 0.0808 - accuracy: 0.9732\n",
            "Epoch 5/30\n",
            "183/183 - 0s - loss: 0.0543 - accuracy: 0.9813\n",
            "Epoch 6/30\n",
            "183/183 - 0s - loss: 0.0527 - accuracy: 0.9815\n",
            "Epoch 7/30\n",
            "183/183 - 0s - loss: 0.0409 - accuracy: 0.9845\n",
            "Epoch 8/30\n",
            "183/183 - 0s - loss: 0.0304 - accuracy: 0.9890\n",
            "Epoch 9/30\n",
            "183/183 - 0s - loss: 0.0306 - accuracy: 0.9885\n",
            "Epoch 10/30\n",
            "183/183 - 0s - loss: 0.0262 - accuracy: 0.9918\n",
            "Epoch 11/30\n",
            "183/183 - 0s - loss: 0.0226 - accuracy: 0.9918\n",
            "Epoch 12/30\n",
            "183/183 - 0s - loss: 0.0184 - accuracy: 0.9947\n",
            "Epoch 13/30\n",
            "183/183 - 0s - loss: 0.0374 - accuracy: 0.9890\n",
            "Epoch 14/30\n",
            "183/183 - 0s - loss: 0.0337 - accuracy: 0.9909\n",
            "Epoch 15/30\n",
            "183/183 - 0s - loss: 0.0166 - accuracy: 0.9945\n",
            "Epoch 16/30\n",
            "183/183 - 0s - loss: 0.0155 - accuracy: 0.9952\n",
            "Epoch 17/30\n",
            "183/183 - 0s - loss: 0.0145 - accuracy: 0.9964\n",
            "Epoch 18/30\n",
            "183/183 - 0s - loss: 0.0057 - accuracy: 0.9993\n",
            "Epoch 19/30\n",
            "183/183 - 0s - loss: 0.0059 - accuracy: 0.9993\n",
            "Epoch 20/30\n",
            "183/183 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "183/183 - 0s - loss: 0.0046 - accuracy: 0.9988\n",
            "Epoch 22/30\n",
            "183/183 - 0s - loss: 0.0047 - accuracy: 0.9990\n",
            "Epoch 23/30\n",
            "183/183 - 0s - loss: 0.0024 - accuracy: 0.9998\n",
            "Epoch 24/30\n",
            "183/183 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "183/183 - 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "183/183 - 0s - loss: 0.0044 - accuracy: 0.9981\n",
            "Epoch 27/30\n",
            "183/183 - 0s - loss: 0.0225 - accuracy: 0.9916\n",
            "Epoch 28/30\n",
            "183/183 - 0s - loss: 0.0638 - accuracy: 0.9858\n",
            "Epoch 29/30\n",
            "183/183 - 0s - loss: 0.0279 - accuracy: 0.9904\n",
            "Epoch 30/30\n",
            "183/183 - 0s - loss: 0.0051 - accuracy: 0.9986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2e87e0f610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EVU5sjXby0M"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZcCOx_6by0N",
        "outputId": "b48bf697-060a-4add-dbbc-f4f4161b3960"
      },
      "source": [
        "# Evaluate the model using the testing data\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
        "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61/61 - 0s - loss: 0.0880 - accuracy: 0.9737\n",
            "Normal Neural Network - Loss: 0.08804664760828018, Accuracy: 0.973738431930542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "avSV9EMzby0N",
        "outputId": "3f4eeb14-80c4-4d35-a9e8-43008d20d390"
      },
      "source": [
        "# Make predictions\n",
        "predicted = model.predict(X_test_scaled)\n",
        "predicted = enc.inverse_transform(predicted).flatten().tolist()\n",
        "results = pd.DataFrame({\n",
        "    \"Actual\": y_test.activity.values,\n",
        "    \"Predicted\": predicted\n",
        "})\n",
        "results.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>walking_upstairs</td>\n",
              "      <td>walking_upstairs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>laying</td>\n",
              "      <td>laying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>walking</td>\n",
              "      <td>walking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lie_to_sit</td>\n",
              "      <td>lie_to_sit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>walking_downstairs</td>\n",
              "      <td>walking_downstairs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>laying</td>\n",
              "      <td>laying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sitting</td>\n",
              "      <td>sitting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Actual           Predicted\n",
              "0    walking_upstairs    walking_upstairs\n",
              "1              laying              laying\n",
              "2             sitting             sitting\n",
              "3             sitting             sitting\n",
              "4             walking             walking\n",
              "5             sitting             sitting\n",
              "6          lie_to_sit          lie_to_sit\n",
              "7  walking_downstairs  walking_downstairs\n",
              "8              laying              laying\n",
              "9             sitting             sitting"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFK018UIby0N",
        "outputId": "38008a70-2de0-4ced-f071-0ec798cbc7e4"
      },
      "source": [
        "# Print the Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(results.Actual, results.Predicted))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "            laying       1.00      1.00      1.00       355\n",
            "        lie_to_sit       0.88      0.93      0.90        15\n",
            "      lie_to_stand       0.82      0.82      0.82        11\n",
            "        sit_to_lie       0.94      0.65      0.77        23\n",
            "      sit_to_stand       1.00      1.00      1.00         4\n",
            "           sitting       0.98      0.93      0.95       337\n",
            "      stand_to_lie       0.65      0.83      0.73        18\n",
            "      stand_to_sit       0.87      0.87      0.87        15\n",
            "          standing       0.94      0.98      0.96       367\n",
            "           walking       1.00      0.99      1.00       300\n",
            "walking_downstairs       1.00      1.00      1.00       230\n",
            "  walking_upstairs       0.98      1.00      0.99       267\n",
            "\n",
            "          accuracy                           0.97      1942\n",
            "         macro avg       0.92      0.92      0.92      1942\n",
            "      weighted avg       0.97      0.97      0.97      1942\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFyaNtWKby0O"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}